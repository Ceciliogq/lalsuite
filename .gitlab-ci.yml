
# -- setup ------------------

stages:
  - tarballs
  # build packages
  - LAL
  - LALFrame
  - LALMetaIO
  - LALSimulation
  - LALBurst
  - LALInspiral
  - LALPulsar
  - LALInference
  - LALApps
  - wheels
  # end-to-end tests
  - integration tests
  - compiler tests
  - platform tests
  - upgrade tests
  # build containers
  - docker
  # quality checks
  - lint
  # documentation
  - documentation
  # deploy packages
  - deploy

include:
  - project: computing/gitlab-ci-templates
    file:
      - /packaging/debian.yml
      - /packaging/rhel.yml
      - /python/lint.yml

# -- global settings --------

image: docker:latest

# by default cache everything under the XDG_CACHE_HOME
cache:
  key: "${CI_JOB_NAME}"
  paths:
    - .cache

variables:
  # gitlab runners have 4 cores per job
  CPU_COUNT: 4
  # don't need git history
  GIT_DEPTH: 1
  # global build helpers
  LAL_DIR: $CI_PROJECT_DIR/opt/lalsuite
  VERBOSE: "true"
  # where to store files
  XDG_CONFIG_HOME: "${CI_PROJECT_DIR}/.config"
  XDG_CACHE_HOME: "${CI_PROJECT_DIR}/.cache"
  CCACHE_DIR: "${XDG_CACHE_HOME}/ccache"
  PIP_CACHE_DIR: "${XDG_CACHE_HOME}/pip"

# -- templates --------------

.configure-ccache: &configure-ccache
  export PATH=/usr/lib/ccache:/opt/local/libexec/ccache:$PATH

.configure-coredump: &configure-coredump
  ulimit -S -c 0

.configure-pkgconfig: &configure-pkgconfig
  export PKG_CONFIG_PATH=${LAL_DIR}/lib/pkgconfig

.configure-nightly: &configure-nightly-build
  if [ ${CI_PIPELINE_SOURCE} = "schedule" ] || [ ${CI_PIPELINE_SOURCE} = "web" ]; then
      export ENABLE_NIGHTLY="--enable-nightly";
  fi

.build-init: &init-build-job
  - *configure-ccache
  - *configure-coredump
  - *configure-nightly-build

.retry: &define-retry |
  retry() {
    local n=1
    local max=3
    local delay=15
    while true; do
      "$@" && break || {
        if [[ $n -lt $max ]]; then
          ((n++))
          echo "Command failed. Attempt $n/$max:"
          sleep $delay;
        else
          echo "The command has failed after $n attempts." 1>&2
          exit 1
        fi
    }
    done
  }

.build-job:
  before_script:
    - *init-build-job

.top-level-build:
  extends:
    - .build-job
  variables:
    CONFIGURE_FLAGS: "--enable-doxygen --enable-swig --enable-python"
    DISTCHECK_CONFIGURE_FLAGS: "${ENABLE_NIGHTLY} ${CONFIGURE_FLAGS}"
    PYTHON: "python3"
  needs: []
  script:
    - ./00boot
    - ./configure ${DISTCHECK_CONFIGURE_FLAGS}
    - make -j${CPU_COUNT} VERBOSE=1 ${MAKE_TARGET:-distcheck}
  artifacts:
    reports:
      junit:
        - "**/*junit*.xml"

.macos:
  tags:
    - macos

# -- build templates ----------------------------

.build-from-tarball:
  variables:
    GIT_STRATEGY: none

# -- rpm

.yum-disable-htcondor-repo: &yum-disable-htcondor-repo
  yum-config-manager --disable htcondor

.rpmbuild:
  extends:
    - .rhel:base
    - .build-from-tarball
  image: igwn/base:el7-testing
  variables:
    RPM_BUILD_NCPUS: ${CPU_COUNT}
    RPM_BUILD_TOPDIR: "${CI_PROJECT_DIR}/rpmbuild"
  # before_script comes from .rhel:base
  script:
    - *init-build-job
    - *yum-disable-htcondor-repo
    # install srpm dependencies
    - yum install -y -q lscsoft-packaging-tools
    # install upstream packages
    - if [ -d rpmbuild ]; then yum install -y -q rpmbuild/RPMS/x86_64/*.rpm; fi
    # build src.rpm
    - PACKAGE=${CI_JOB_NAME%%:*}
    - cd ${PACKAGE}/
    - TARBALL=$(ls -t1 ${PACKAGE}-*.tar.* | head -n1 | xargs readlink -f)
    - rpmbuild -ts --define "_topdir ${RPM_BUILD_TOPDIR}" ${TARBALL}
    - SRPM=${RPM_BUILD_TOPDIR}/SRPMS/${PACKAGE}-*.src.rpm
    # install build dependencies
    - yum-builddep -y -q ${SRPM}
    # build binary rpms and print details of what we got
    - rpmbuild --rebuild --define "_topdir ${RPM_BUILD_TOPDIR}" ${SRPM}
    # print package info
    - set +x
    - for rpmf in ${CI_PROJECT_DIR}/rpmbuild/RPMS/*/*${PACKAGE}-*.rpm; do
          echo "===== ${rpmf}" &&
          rpm -qlp "${rpmf}" &&
          echo "Files:" &&
          rpm -qip "${rpmf}" &&
          echo "Provides:" &&
          rpm -qp --provides "${rpmf}" &&
          echo "Requires:" &&
          rpm -qp --requires "${rpmf}";
      done
    # lint RPMs
    - |
      cat << EOF > rpmlintrc
      # don't validate Source0
      setOption("NetworkEnabled", False)
      # don't know how to fix this
      addFilter('binary-or-shlib-defines-rpath')
      # the regex rpmlint uses to identify 'lib' libraries is crap
      addFilter('explicit-lib-dependency (.*)?matplotlib')
      addFilter('explicit-lib-dependency (.*)?ciecplib')
      EOF
    - rpmlint
          -f rpmlintrc
          ${CI_PROJECT_DIR}/rpmbuild/RPMS/*/*${PACKAGE}-*.rpm
  artifacts:
    expire_in: 18h
    paths:
      # build packages
      - "rpmbuild/RPMS/x86_64/${CI_JOB_NAME%%:*}-*.rpm"
      - "rpmbuild/RPMS/x86_64/lib${CI_JOB_NAME%%:*}-*.rpm"
      - "rpmbuild/RPMS/x86_64/python*-${CI_JOB_NAME%%:*}-*.rpm"
      # log files
      - "rpmbuild/BUILD/*/config.log"
      - "rpmbuild/BUILD/**/test-suite.log"
    reports:
      junit: "rpmbuild/BUILD/**/*junit*.xml"
    when: always
  only:
    refs:
      - pushes
      - schedules
      - tags
      - web
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip rhel\]/

# -- debian

.debuild:
  extends:
    - .debian:base
    - .build-from-tarball
  image: igwn/base:buster
  variables:
    DEB_BUILD_OPTIONS: "parallel=${CPU_COUNT}"
  # before_script: comes from .debian:base
  script:
    - *init-build-job
    - PACKAGE=${CI_JOB_NAME%%:*}
    # install build requirements
    - apt-get install -y -q -q
          devscripts
          dpkg-dev
          lintian
    # install upstream packages
    - "ls *.deb &>/dev/null && { dpkg -i *.deb || { apt-get -y -f install; dpkg -i *.deb; } }"
    # create orig tarball
    - cd ${PACKAGE}/
    - TARBALL=$(ls -t1 ${PACKAGE}-*.tar.* | head -n1 | xargs readlink -f)
    - SUFFIX=$(basename $TARBALL | sed 's/.*\.\(tar\..*\)/\1/')
    - VERSION=$(basename $TARBALL | sed 's/[^-]*-\(.*\)\.tar\..*/\1/' | tr '-' '~')
    - cd ${CI_PROJECT_DIR}/
    - cp ${TARBALL} ${PACKAGE}_${VERSION}.orig.${SUFFIX}
    # unpack tarball
    - export DEBFULLNAME="GitLab"
    - export DEBEMAIL="gitlab@git.ligo.org"
    - tar -xf ${TARBALL}
    - cd ${PACKAGE}-*/
    # update changelog
    - dch -v ${VERSION}-1 -b 'Rebuilt automatically on git.ligo.org CI'
    # install build dependencies
    - mk-build-deps
          --tool "apt-get -y -q -o Debug::pkgProblemResolver=yes --no-install-recommends"
          --install
          --remove
    # build packages
    - debuild
         -us -uc -r
         --lintian-opts --color=always --allow-root
    # print package info
    - set +x
    - cd ${CI_PROJECT_DIR}
    - for debf in *.deb; do
          echo "===== ${debf}";
          dpkg --info "${debf}";
          dpkg --contents "${debf}";
      done
  artifacts:
    expire_in: 18h
    paths:
      # build packages
      - "${CI_JOB_NAME%%:*}*.changes"
      - "${CI_JOB_NAME%%:*}*.deb"
      - "lib${CI_JOB_NAME%%:*}*.deb"
      - "python*-${CI_JOB_NAME%%:*}*.deb"
      - "${CI_JOB_NAME%%:*}*.dsc"
      # log files
      - "${CI_JOB_NAME%%:*}*/**/config.log"
      - "${CI_JOB_NAME%%:*}*/**/test-suite.log"
      # the orig tarball
      - "${CI_JOB_NAME%%:*}*.orig.*"
    reports:
      junit: "${CI_JOB_NAME%%:*}*/.pybuild/python*/build/**/*junit*.xml"
    when: always
  only:
    refs:
      - pushes
      - schedules
      - tags
      - web
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip debian\]/

# -- conda

.conda-init: &conda-init
  - *define-retry
  # init conda
  - mkdir -p $(dirname ${CONDA_PKGS_DIRS:=${CI_PROJECT_DIR/.cache/conda/pkgs}})
  - source ${CONDA_ROOT:=/opt/conda}/etc/profile.d/conda.sh
  # configure conda options
  - conda config --set always_yes yes
  - conda config --add channels conda-forge
  - conda config --set channel_priority strict
  # update conda itself
  - retry conda update -n base conda setuptools
  # install build helpers
  - retry conda install -n base "conda-build!=3.18.10" conda-forge-pinning "conda-smithy>=3.7.5" conda-verify
  # print info
  - conda activate base
  - conda info --all

.conda-job:
  image: igwn/base:conda
  variables:
    CONDA_BLD_PATH: "${CI_PROJECT_DIR}/conda-bld"
    CONDA_PKGS_DIRS: "${XDG_CACHE_HOME}/conda/pkgs"
    GIT_STRATEGY: none
  before_script:
    - *init-build-job
    - *define-retry
    - *conda-init

.conda-build:
  extends:
    - .conda-job
  variables:
    CONDA_CONFIG: "linux_64_"
    CONDA_PYTHON_VERSION: "3.8"
  script:
    - PACKAGE=${CI_JOB_NAME%%:*}
    - cd ${PACKAGE}/
    # render YAML file to use our tarball
    - TARBALL=$(ls -t1 ${PACKAGE}-*.tar.* | head -n1 | xargs readlink -f)
    - SHA256=$(openssl dgst -r -sha256 $TARBALL | cut -d\  -f1)
    - tar -xf ${TARBALL} --wildcards ${PACKAGE}-*/conda/ --strip-components=1
    - sed 's|@TARBALL@|'${TARBALL}'|g' conda/meta.yaml.in > conda/meta.yaml
    - sed -i 's|@SHA256@|'${SHA256}'|g' conda/meta.yaml
    # create a feedstock from the conda recipe
    - git config --global user.name "${GITLAB_USER_NAME}"
    - git config --global user.email "${GITLAB_USER_EMAIL}"
    - conda smithy init conda/ --feedstock-directory ${PACKAGE}-feedstock
    - cd ${PACKAGE}-feedstock
    - retry conda smithy regenerate --no-check-uptodate
    - git ls-files
    # build packages (preferring local packages over everything)
    # note: we use a variable and `eval` to get around the
    #       _pyversion string having spaces in it
    - cmd="conda build
          recipe/
          --dirty
          --error-overlinking
          --error-overdepending
          --keep-old-work
          --no-anaconda-upload
          --use-channeldata
          --use-local
          --variant-config-files .ci_support/${CONDA_CONFIG}.yaml
          ${CONDA_BUILD_ARGS}"
    # if not a nightly or web-triggered pipeline, just build one python version
    - if [ ${CI_PIPELINE_SOURCE} != "schedule" ] && [ ${CI_PIPELINE_SOURCE} != "web" ]; then
         cmd="${cmd} --python \"${CONDA_PYTHON_VERSION}.* *_cpython\"";
      fi
    # run the build
    - echo $cmd && eval $cmd
  after_script:
    # clean cache of old files
    - find ${CONDA_PKGS_DIRS%:*} -atime +30 -delete
    - find ${CONDA_PKGS_DIRS%:*} -type d -empty -delete
  artifacts:
    expire_in: 18h
    paths:
      # built packages (matching this package only)
      - "conda-bld/**/${CI_JOB_NAME%%:*}-*.conda"
      - "conda-bld/**/${CI_JOB_NAME%%:*}-*.tar.bz2"
      - "conda-bld/**/lib${CI_JOB_NAME%%:*}-*.conda"
      - "conda-bld/**/lib${CI_JOB_NAME%%:*}-*.tar.bz2"
      - "conda-bld/**/python-${CI_JOB_NAME%%:*}-*.conda"
      - "conda-bld/**/python-${CI_JOB_NAME%%:*}-*.tar.bz2"
      # log files
      - "conda-bld/${CI_JOB_NAME%%:*}-*/work/_build*/config.log"
      - "conda-bld/${CI_JOB_NAME%%:*}-*/work/**/test-suite.log"
      # the feedstock
      - "${CI_JOB_NAME%%:*}/${CI_JOB_NAME%%:*}-feedstock/"
    reports:
      junit: "conda-bld/${CI_JOB_NAME%%:*}-*/**/*junit*.xml"
    when: always
  only:
    refs:
      - pushes
      - schedules
      - tags
      - web
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip conda\]/

# -- tarballs -----------------------------------

.make-dist:
  image: igwn/lalsuite-dev:el7
  stage: tarballs
  extends:
    - .top-level-build
  script:
    - pushd ${CI_JOB_NAME##*:}
    - ./00boot
    - ./configure ${ENABLE_NIGHTLY} --enable-swig
    - make dist
  artifacts:
    expire_in: 18h
    paths:
      - "*/*.tar.*"

make-dist:
  extends:
    - .make-dist
  script:
    - ./00boot
    - ./configure ${ENABLE_NIGHTLY} --enable-swig
    - for subdir in lal lalframe lalmetaio lalsimulation lalburst lalinspiral lalpulsar lalinference lalapps; do
        pushd ${subdir};
        make dist;
        popd;
      done

# just make the lal tarball to release other jobs
make-dist:lal:
  extends:
    - .make-dist

# -- lal ----------------------------------------

.lal:
  stage: LAL
  needs:
    - make-dist:lal

lal:rpm:
  extends:
     - .rpmbuild
     - .lal

lal:deb:
  extends:
    - .debuild
    - .lal

lal:conda:fftw:
  extends:
    - .conda-build
    - .lal
  variables:
    CONDA_CONFIG: "linux_64_fft_implfftw"

lal:conda:mkl:
  extends:
    - .conda-build
    - .lal
  variables:
    CONDA_CONFIG: "linux_64_fft_implmkl"

# -- lalframe------------------------------------

.lalframe:
  stage: LALFrame

lalframe:rpm:
  extends:
    - .rpmbuild
    - .lalframe
  needs:
    - make-dist
    - lal:rpm

lalframe:deb:
  extends:
    - .debuild
    - .lalframe
  needs:
    - make-dist
    - lal:deb

lalframe:conda:
  extends:
    - .conda-build
    - .lalframe
  needs:
    - make-dist
    - lal:conda:fftw

# -- lalmetaio ----------------------------------

.lalmetaio:
  stage: LALMetaIO

lalmetaio:rpm:
  extends:
    - .rpmbuild
    - .lalmetaio
  needs:
    - make-dist
    - lal:rpm

lalmetaio:deb:
  extends:
    - .debuild
    - .lalmetaio
  needs:
    - make-dist
    - lal:deb

lalmetaio:conda:
  extends:
    - .conda-build
    - .lalmetaio
  needs:
    - make-dist
    - lal:conda:fftw

# -- lalsimulation ------------------------------

.lalsimulation:
  stage: LALSimulation

lalsimulation:rpm:
  extends:
    - .rpmbuild
    - .lalsimulation
  needs:
    - make-dist
    - lal:rpm

lalsimulation:deb:
  extends:
    - .debuild
    - .lalsimulation
  needs:
    - make-dist
    - lal:deb

lalsimulation:conda:
  extends:
    - .conda-build
    - .lalsimulation
  needs:
    - make-dist
    - lal:conda:fftw

# -- lalburst -----------------------------------

.lalburst:
  stage: LALBurst

lalburst:rpm:
  extends:
    - .rpmbuild
    - .lalburst
  needs:
    - make-dist
    - lal:rpm
    - lalmetaio:rpm
    - lalsimulation:rpm

lalburst:deb:
  extends:
    - .debuild
    - .lalburst
  needs:
    - make-dist
    - lal:deb
    - lalmetaio:deb
    - lalsimulation:deb

lalburst:conda:
  extends:
    - .conda-build
    - .lalburst
  needs:
    - make-dist
    - lal:conda:fftw
    - lalmetaio:conda
    - lalsimulation:conda

# -- lalinspiral --------------------------------

.lalinspiral:
  stage: LALInspiral

lalinspiral:rpm:
  extends:
    - .rpmbuild
    - .lalinspiral
  needs:
    - make-dist
    - lal:rpm
    - lalframe:rpm
    - lalmetaio:rpm
    - lalsimulation:rpm
    - lalburst:rpm

lalinspiral:deb:
  extends:
    - .debuild
    - .lalinspiral
  needs:
    - make-dist
    - lal:deb
    - lalframe:deb
    - lalmetaio:deb
    - lalsimulation:deb
    - lalburst:deb

lalinspiral:conda:
  extends:
    - .conda-build
    - .lalinspiral
  needs:
    - make-dist
    - lal:conda:fftw
    - lalframe:conda
    - lalmetaio:conda
    - lalsimulation:conda
    - lalburst:conda

# -- lalpulsar ----------------------------------

.lalpulsar:
  stage: LALPulsar

lalpulsar:rpm:
  extends:
    - .rpmbuild
    - .lalpulsar
  needs:
    - make-dist
    - lal:rpm

lalpulsar:deb:
  extends:
    - .debuild
    - .lalpulsar
  needs:
    - make-dist
    - lal:deb

lalpulsar:conda:
  extends:
    - .conda-build
    - .lalpulsar
  needs:
    - make-dist
    - lal:conda:fftw

# -- lalinference -------------------------------

.lalinference:
  stage: LALInference

lalinference:rpm:
  extends:
    - .rpmbuild
    - .lalinference
  needs:
    - make-dist
    - lal:rpm
    - lalframe:rpm
    - lalmetaio:rpm
    - lalsimulation:rpm
    - lalburst:rpm
    - lalpulsar:rpm
    - lalinspiral:rpm

lalinference:deb:
  extends:
    - .debuild
    - .lalinference
  needs:
    - make-dist
    - lal:deb
    - lalframe:deb
    - lalmetaio:deb
    - lalsimulation:deb
    - lalburst:deb
    - lalpulsar:deb
    - lalinspiral:deb

lalinference:conda:
  extends:
    - .conda-build
    - .lalinference
  needs:
    - make-dist
    - lal:conda:fftw
    - lalframe:conda
    - lalmetaio:conda
    - lalsimulation:conda
    - lalburst:conda
    - lalpulsar:conda
    - lalinspiral:conda

# -- lalapps ------------------------------------

.lalapps:
  stage: LALApps

lalapps:rpm:
  extends:
    - .rpmbuild
    - .lalapps
  needs:
    - make-dist
    - lal:rpm
    - lalframe:rpm
    - lalmetaio:rpm
    - lalsimulation:rpm
    - lalburst:rpm
    - lalpulsar:rpm
    - lalinspiral:rpm
    - lalinference:rpm

lalapps:deb:
  extends:
    - .debuild
    - .lalapps
  needs:
    - make-dist
    - lal:deb
    - lalframe:deb
    - lalmetaio:deb
    - lalsimulation:deb
    - lalburst:deb
    - lalpulsar:deb
    - lalinspiral:deb
    - lalinference:deb

lalapps:conda:
  extends:
    - .conda-build
    - .lalapps
  needs:
    - make-dist
    - lal:conda:fftw
    - lalframe:conda
    - lalmetaio:conda
    - lalsimulation:conda
    - lalburst:conda
    - lalpulsar:conda
    - lalinspiral:conda
    - lalinference:conda
  variables:
    CONDA_CONFIG: "linux_64_python${CONDA_PYTHON_VERSION}.____cpython"

# -- wheels -------------------------------------

.wheel:
  stage: wheels
  needs: []
  extends:
    - .build-job
  only:
    refs:
      - /^lalsuite-v.*$/
      - schedules
      - web
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip wheels\]/
  artifacts:
    expire_in: 18h
    paths:
      - wheelhouse

.wheel-test: &wheel-test
  # do some simple sanity checks in a virtualenv
  - ${PYTHON} -m venv test
  - source test/bin/activate
  - python -m pip install --upgrade pip
  - python -m pip install wheelhouse/*
  - |
    python3 - <<EOF
    import lal
    import lalframe
    import lalmetaio
    import lalsimulation
    series = lal.CreateREAL8FrequencySeries('psd', 0, 0, 1, None, 4096)
    lalsimulation.SimNoisePSDaLIGOAPlusDesignSensitivityT1800042(series, 10)
    EOF
  - lalapps_version

# Build receipe for standalone wheels on Linux
.wheel:manylinux:
  extends:
    - .wheel
  script:
    - export PYTHON="/opt/python/$(echo ${CI_JOB_NAME} | sed 's/.*:\(.*\)-manylinux.*/\1/')/bin/python"
    # Build wheel
    - ./00boot
    - ./configure
          ${ENABLE_NIGHTLY}
          --disable-doxygen
          --disable-swig-octave
          --enable-mpi
          --enable-python
          --enable-swig-python
          PYTHON=${PYTHON}
    - make -j${CPU_COUNT} wheel
    # Bundle and fix up dependent shared libraries
    - auditwheel repair wheel/*.whl
    # Test: do some simple sanity checks in a virtualenv
    - *wheel-test

# Build receipe for standalone wheels on macOS
.wheel:macos:
  extends:
    - .wheel
  tags:
    - macos_sierra
  script:
    - PYTHON=$(which python$(echo ${CI_JOB_NAME} | sed 's/.*:cp\(.\)\(.\).*/\1.\2/'))
    # Enter virtualenv so that we have a controlled version of Numpy
    - ${PYTHON} -m venv env
    - source env/bin/activate
    - python -m pip install
          git+https://github.com/lpsinger/delocate@fix-duplicate-libs
          oldest-supported-numpy
    # Build wheel
    - ./00boot
    - ./configure
          ${ENABLE_NIGHTLY}
          --disable-doxygen
          --disable-swig-octave
          --enable-mpi
          --enable-python
          --enable-swig-python
          PYTHON=$(which python)
          LDFLAGS=-Wl,-headerpad_max_install_names
    - make -j${CPU_COUNT} wheel
    # Bundle and fix up dependent shared libraries
    - delocate-wheel -v -w wheelhouse wheel/*.whl
    # Test: do some simple sanity checks in a virtualenv
    - *wheel-test
  only:
    # don't run macos wheel jobs from manually-triggered pipelines
    refs:
      - /^lalsuite-v.*$/
      - schedules

.wheel:manylinux2014:
  extends:
    - .wheel:manylinux
  image: containers.ligo.org/lscsoft/lalsuite-manylinux/manylinux2014_x86_64

# Build wheels for all supported platforms
wheel:cp36-cp36m-manylinux2014:
  extends:
    - .wheel:manylinux2014
wheel:cp37-cp37m-manylinux2014:
  extends:
    - .wheel:manylinux2014
wheel:cp38-cp38-manylinux2014:
  extends:
    - .wheel:manylinux2014
wheel:cp39-cp39-manylinux2014:
 extends:
    - .wheel:manylinux2014
wheel:cp36-cp36m-macosx:
  extends:
    - .wheel:macos
wheel:cp37-cp37m-macosx:
  extends:
    - .wheel:macos
wheel:cp38-cp38-macosx:
  extends:
    - .wheel:macos
wheel:cp39-cp39-macosx:
 extends:
    - .wheel:macos

# -- integration tests --------------------------

.integration-tests:
  stage: integration tests
  only:
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip integration\]/

lalinference_testjob:
  extends:
    - .integration-tests
  image: igwn/base:el7-testing
  before_script:
    - *yum-disable-htcondor-repo
    - yum -y -q install
          git
          git-lfs
    - yum -y -q install rpmbuild/RPMS/x86_64/*.rpm
  script:
    - git lfs clone https://git.ligo.org/lscsoft/ROQ_data --include "**/params.dat,*/4s/**"
    - bash lalinference/test/lalinference_nestedSampling_integration_test.sh
  needs:
    - lal:rpm
    - lalframe:rpm
    - lalmetaio:rpm
    - lalsimulation:rpm
    - lalburst:rpm
    - lalpulsar:rpm
    - lalinspiral:rpm
    - lalinference:rpm
  only:
    refs:
      - schedules
      - web
  artifacts:
    expire_in: 18h
    paths:
      - example/
    when: always

top-level:
  image: igwn/lalsuite-dev:el7-testing
  needs: []
  extends:
    - .top-level-build
    - .integration-tests
  only:
    refs:
      - pushes
      - schedules
      - web

# Note: adapted from https://git.ligo.org/lscsoft/ligo.skymap
coverage:
  extends:
    - .integration-tests
  image: igwn/lalsuite-dev-gcc:8
  needs: []
  before_script:
    - *init-build-job
    - apt-get -y install --no-install-recommends python3-pip
    - python3 -m pip install coverage gcovr pycobertura
  script:
    - ./00boot
    # Configure for C code coverage measurement with gcc
    - ./configure
          ${ENABLE_NIGHTLY}
          --enable-swig-python
          CFLAGS="--coverage -fprofile-abs-path"
          PYTHON=python3
    # Run unit tests with Python scripts instrumented by coverage.py
    - make -j${CPU_COUNT} check COVERAGE_FILE="$(pwd)/.coverage" PY_LOG_FLAGS="-m coverage run --source \"$(pwd)\" --omit \*/test/\* -p"
  after_script:
    # Output C coverage data in Cobertura format
    - gcovr -j${CPU_COUNT} --exclude-directories test --xml c-coverage.xml
    # Combine and output Python coverage data in Cobertura format
    - python3 -m coverage combine
    - python3 -m coverage xml -o py-coverage.xml
    # Merge coverage reports. They're just XML, after all.
    - |
      python3 - <<EOF
      import lxml.etree
      import copy

      doc1 = lxml.etree.parse('py-coverage.xml')
      doc2 = lxml.etree.parse('c-coverage.xml')
      root1 = doc1.getroot()
      root2 = doc2.getroot()
      root1.attrib['lines-covered'] = str(
          int(root1.attrib['lines-covered']) +
          int(root2.attrib['lines-covered']))
      root1.attrib['lines-valid'] = str(
          int(root1.attrib['lines-valid']) +
          int(root2.attrib['lines-valid']))
      try:
          root1.attrib['line-rate'] = str(
              int(root1.attrib['lines-covered']) /
              int(root1.attrib['lines-valid']))
      except ZeroDivisionError:
          root1.attrib['line-rate'] = '0'
      root1.attrib['branches-covered'] = str(
          int(root1.attrib['branches-covered']) +
          int(root2.attrib['branches-covered']))
      root1.attrib['branches-valid'] = str(
          int(root1.attrib['branches-valid']) +
          int(root2.attrib['branches-valid']))
      try:
          root1.attrib['branch-rate'] = str(
              int(root1.attrib['branches-covered']) /
              int(root1.attrib['branches-valid']))
      except ZeroDivisionError:
          root1.attrib['branch-rate'] = '0'
      packages = root1.find('./packages')
      packages.extend(root2.iterfind('./packages/package'))
      doc1.write('coverage.xml')
      EOF
    # Write HTML coverage report and show coverage summary.
    - pycobertura show coverage.xml -f html -o coverage.html
    - pycobertura show coverage.xml | tail -n 1
  coverage: '/TOTAL\s+.*\s+([\d\.]+)%/'
  artifacts:
    paths:
      - coverage.html
    reports:
      cobertura: coverage.xml
  only:
    refs:
      - pushes
      - schedules
      - web

# -- compiler tests -----------------------------

.compiler-test:
  stage: compiler tests
  needs: []
  extends:
    - .top-level-build
  variables:
    MAKE_TARGET: "distcheck"
  only:
    - schedules
    - web

clang:10:
  extends:
    - .compiler-test
  image: igwn/lalsuite-dev-clang:10
  variables:
    CC: clang-10
    CXX: clang++-10

clang:11:
  extends:
    - .compiler-test
  image: igwn/lalsuite-dev-clang:11
  variables:
    CC: clang-11
    CXX: clang++-11

clang:dev:
  extends:
    - .compiler-test
  image: igwn/lalsuite-dev-clang:dev
  variables:
    CC: clang
    CXX: clang++

.compiler-test:gcc:
  extends:
    - .compiler-test
  variables:
    CONFIGURE_FLAGS: "--enable-doxygen --enable-swig --enable-python --disable-swig-octave"

gcc:7:
  extends:
    - .compiler-test:gcc
  image: igwn/lalsuite-dev-gcc:7

gcc:8:
  extends:
    - .compiler-test:gcc
  image: igwn/lalsuite-dev-gcc:8

gcc:9:
  extends:
    - .compiler-test:gcc
  image: igwn/lalsuite-dev-gcc:9

gcc:10:
  extends:
    - .compiler-test:gcc
  image: igwn/lalsuite-dev-gcc:10
  allow_failure: true

cuda:
  extends:
    - .compiler-test
  image: igwn/lalsuite-dev-cuda:el7
  script:
    - ./00boot
    - ./configure --with-cuda=/usr/local/cuda
    - make -j${CPU_COUNT} dist
    - make -j${CPU_COUNT}
    # just compile test suite; some tests require a CUDA device to run
    - make -j${CPU_COUNT} VERBOSE=1 check TESTS=
    - make -j${CPU_COUNT} install
  allow_failure: true

# -- upgrade tests ----------

.upgrade-test:
  stage: upgrade tests
  artifacts: {}

upgrade:rpm:el7:
  extends:
    - .rpmbuild
    - .upgrade-test
  needs:
    - lal:rpm
    - lalframe:rpm
    - lalmetaio:rpm
    - lalsimulation:rpm
    - lalburst:rpm
    - lalpulsar:rpm
    - lalinspiral:rpm
    - lalinference:rpm
    - lalapps:rpm
  script:
    - *yum-disable-htcondor-repo
    # install latest release
    - yum -y -q install lalapps
    # install new packages
    - yum -y -q install rpmbuild/RPMS/x86_64/*.rpm

upgrade:debian:buster:
  extends:
    - .debuild
    - .upgrade-test
  needs:
    - lal:deb
    - lalframe:deb
    - lalmetaio:deb
    - lalsimulation:deb
    - lalburst:deb
    - lalpulsar:deb
    - lalinspiral:deb
    - lalinference:deb
    - lalapps:deb
  script:
    - apt-get -y -q -q update
    # install latest lalsuite release
    - apt-get -y -q install lscsoft-lalsuite
    # setup local apt repository
    - apt-get -y -q install local-apt-repository
    - mkdir /srv/local-apt-repository
    - cp *.deb /srv/local-apt-repository
    - /usr/lib/local-apt-repository/rebuild
    # install new packages
    - apt-get -y -q update
    - apt-get -y -q dist-upgrade

upgrade:conda:linux:
  extends:
    - .conda-build
    - .upgrade-test
  needs:
    - lal:conda:fftw
    - lalframe:conda
    - lalmetaio:conda
    - lalsimulation:conda
    - lalburst:conda
    - lalpulsar:conda
    - lalinspiral:conda
    - lalinference:conda
    - lalapps:conda
  script:
    # properly index the newly built packages
    - conda index ${CONDA_BLD_PATH}
    # install latest release
    - conda create -n upgrade-test --only-deps lalsuite
    # install new packages
    - conda update -n upgrade-test --use-local
          lal
          lalframe
          lalmetaio
          lalsimulation
          lalburst
          lalinspiral
          lalpulsar
          lalinference
          lalapps

# -- platform tests ---------

.platform-test:
  stage: platform tests
  extends:
    - .top-level-build
  only:
    - schedules
    - web

platform:debian:stretch:
  extends:
    - .platform-test
  image: igwn/lalsuite-dev:stretch-proposed

.platform-test:conda:
  extends:
    - .platform-test
  variables:
    CONFIGURE_FLAGS: "--disable-swig-octave --enable-python --enable-swig-python"
  before_script:
    - source ${CONDA_ROOT:-/opt/conda}/etc/profile.d/conda.sh
    - conda env create
          --file conda/environment-lal-development-py37.yml
          --name lalsuite-platform-tests
          --quiet
    - conda info --all
    - conda list --name lalsuite-platform-tests
    - conda activate lalsuite-platform-tests
  allow_failure: true

platform:conda:linux:
  image: igwn/base:conda
  extends:
    - .platform-test:conda

platform:conda:macos:
  extends:
    - .platform-test:conda
    - .macos

# -- docker -------------------------------------

.docker:
  variables:
    DOCKER_DRIVER: overlay
  stage: docker
  only:
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip docker\]/
  script:
    # build container and push to registry
    - IMAGE_TAG=${CI_JOB_NAME##*:}
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
    - docker build --pull -t ${IMAGE_NAME}:${IMAGE_TAG} --file ${DOCKER_FILE} .
    - docker push ${IMAGE_NAME}

.docker:nightly:
  extends:
    - .docker
  variables:
    IMAGE_NAME: "$CI_REGISTRY_IMAGE/nightly"
  only:
    refs:
      - schedules

.docker:tags:
  extends:
    - .docker
  variables:
    IMAGE_NAME: "$CI_REGISTRY_IMAGE/$CI_COMMIT_TAG"
  only:
    refs:
      - /^lalsuite-v.*$/

.docker:el:
  extends:
    - .docker
  variables:
    DOCKER_FILE: ".gitlab-ci-el7.Dockerfile"
  before_script:
    - set -x
    # add RPMs to directory to pass to docker
    - mkdir rpms && mv rpmbuild/RPMS/x86_64/*.rpm rpms
    - rm -rf rpmbuild*
  needs:
    - lal:rpm
    - lalframe:rpm
    - lalmetaio:rpm
    - lalsimulation:rpm
    - lalburst:rpm
    - lalpulsar:rpm
    - lalinspiral:rpm
    - lalinference:rpm
    - lalapps:rpm

.docker:debian:
  extends:
    - .docker
  variables:
    DOCKER_FILE: ".gitlab-ci-buster.Dockerfile"
  before_script:
    - set -x
    # add deb packages to directory to pass to docker
    - mkdir debs && mv *.deb debs
    - rm *.changes *.dsc *.orig.*
  needs:
    - lal:deb
    - lalframe:deb
    - lalmetaio:deb
    - lalsimulation:deb
    - lalburst:deb
    - lalpulsar:deb
    - lalinspiral:deb
    - lalinference:deb
    - lalapps:deb

# build a nightly container from the RPMs
docker:nightly:el7:
  extends:
    - .docker:el
    - .docker:nightly

# build a tagged container from the rpms
docker:tags:el7:
  extends:
    - .docker:el
    - .docker:tags

docker:nightly:buster:
  extends:
    - .docker:debian
    - .docker:nightly

docker:tags:buster:
  extends:
    - .docker:debian
    - .docker:tags

# -- linting ------------------------------------

.lint:
  stage: lint
  needs: []
  only:
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip lint\]/

lint:python:
  extends:
    - .python:flake8
    - .lint
  # use everything we get from .python:flake8

lint:coala:
  extends:
    - .lint
  image: coala/base
  script:
    # run first for codeclimate (using --json)
    - coala --ci --json -o coala.json || true
    # run again to get plaintxt output for the user
    - coala --ci
  after_script:
    - |
      python3 - <<EOF
      import json
      import sys
      SEVERITY = ['info', 'minor', 'major', 'critical', 'blocker']
      with open('coala.json', 'r') as file:
          indata = json.load(file)
      outdata = []
      for key in indata['results']:
          for e in indata['results'][key]:
              start = e['affected_code'][0]['start']
              end = e['affected_code'][0]['end']
              outdata.append({
                  'type': 'issue',
                  'check_name': e['origin'],
                  'content': e['additional_info'] or None,
                  'description': e['message'],
                  'fingerprint': e['id'],
                  'severity': SEVERITY[e['severity']],
                  'location': {
                      'path': start['file'],
                      'begin': start['line'],
                      'end': end['line'],
                  },
              })
      with open('codequality.json', 'w') as file:
          json.dump(outdata, file, separators=(',', ':'))
      EOF
  artifacts:
    paths:
      - output.json
      - codequality.json
    reports:
      codequality: codequality.json
    expire_in: 1month
    when: always

# -- documentation ------------------------------

documentation:
  image: igwn/lalsuite-dev:buster
  stage: documentation
  needs: []
  script:
    - ./00boot
    - ./configure --enable-doxygen --prefix=$(pwd)/_inst
    - make -j${CPU_COUNT} install-html
    - mv _inst/share/doc html
    - cd html
    - cp lalsuite/index.html index.html
    - sed -i 's/..\/lal/lal/g' index.html
  artifacts:
    expire_in: 18h
    paths:
      - html
  only:
    refs:
      - pushes
      - web
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip docs\]/

# -- deploy -----------------

# deploy documentation to gitlab pages
pages:
  image: igwn/lalsuite-dev:buster
  stage: deploy
  needs:
    - documentation
    - coverage
  script:
    - mv html public
    - cp coverage.html public/
  artifacts:
    paths:
      - public
  only:
    refs:
      - master@lscsoft/lalsuite
    variables:
      - $CI_COMMIT_MESSAGE !~ /\[skip docs\]/
  except:
    refs:
      - pushes
      - web

# deploy wheels
deploy:wheel:
  stage: deploy
  image: python
  variables:
    GIT_STRATEGY: none
  script:
    # exit if we're not running in the main namespace
    - if [[ ${CI_PROJECT_PATH} != "lscsoft/lalsuite" ]]; then echo "Not deploying."; exit 0; fi
    # TWINE_USERNAME and TWINE_PASSWORD are provided by CI secret variables
    - pip install twine
    - twine upload wheelhouse/*
  needs:
    - wheel:cp36-cp36m-manylinux2014
    - wheel:cp37-cp37m-manylinux2014
    - wheel:cp38-cp38-manylinux2014
    - wheel:cp39-cp39-manylinux2014
    - wheel:cp36-cp36m-macosx
    - wheel:cp37-cp37m-macosx
    - wheel:cp38-cp38-macosx
    - wheel:cp39-cp39-macosx
  only:
    refs:
      - /^lalsuite-v.*$/
      - schedules
